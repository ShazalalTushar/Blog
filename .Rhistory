plt.legend()
plt.show()
from sklearn.ensemble import RandomForestRegressor
# Create and train the Random Forest Regression model
model = RandomForestRegressor(n_estimators=100, random_state=42)
model.fit(X_train, y_train)
# Make predictions on the test set
y_pred_rf = model.predict(X_test)
# Evaluate the model
r2_rf = r2_score(y_test, y_pred)
print(f'R-squared of RF (RÂ²): {r2_rf:.2f}')
import pandas as pd
import numpy as np
import numpy as np
import matplotlib.pyplot as plt
from sklearn import datasets
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import warnings
warnings.simplefilter("ignore")
#import the iris dataset
iris = datasets.load_iris()
X = iris.data
y = iris.target
iris.info()
import pandas as pd
import numpy as np
import numpy as np
import matplotlib.pyplot as plt
from sklearn import datasets
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import warnings
warnings.simplefilter("ignore")
#import the iris dataset
iris = datasets.load_iris()
X = iris.data
y = iris.target
X, y
import pandas as pd
import numpy as np
import numpy as np
import matplotlib.pyplot as plt
from sklearn import datasets
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import warnings
warnings.simplefilter("ignore")
#import the iris dataset
iris = datasets.load_iris()
X = iris.data
y = iris.target
iris.isnull().sum()
import pandas as pd
import numpy as np
import numpy as np
import matplotlib.pyplot as plt
from sklearn import datasets
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import warnings
warnings.simplefilter("ignore")
#import the iris dataset
iris = datasets.load_iris()
X = iris.data
y = iris.target
iris.null().sum()
import pandas as pd
import numpy as np
import numpy as np
import matplotlib.pyplot as plt
from sklearn import datasets
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import warnings
warnings.simplefilter("ignore")
#import the iris dataset
iris = datasets.load_iris()
X = iris.data
y = iris.target
iris.columns
import pandas as pd
import numpy as np
import numpy as np
import matplotlib.pyplot as plt
from sklearn import datasets
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.linear_model import LogisticRegression
import warnings
warnings.simplefilter("ignore")
#import the iris dataset
iris = datasets.load_iris()
X = iris.data
y = iris.target
from sklearn.model_selection import train_test_split
X_train, X_test, y_train,y_test= train_test_split(X,y,random_state=0)
model= LogisticRegression()
model.fit(X_train,y_train)
y_pred= model.predict(X_test)
y_pred
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn import datasets
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import confusion_matrix
# Load the iris dataset
iris = datasets.load_iris()
X = iris.data
y = iris.target
# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)
# Train a logistic regression model
model = LogisticRegression()
model.fit(X_train, y_train)
# Make predictions on the test set
y_pred = model.predict(X_test)
# Generate confusion matrix
conf_matrix = confusion_matrix(y_test, y_pred)
# Create a DataFrame for better visualization
conf_df = pd.DataFrame(conf_matrix, index=iris.target_names, columns=iris.target_names)
# Create a heatmap using Seaborn
plt.figure(figsize=(8, 6))
sns.heatmap(conf_df, annot=True, cmap='Blues', fmt='g')
plt.title('Confusion Matrix Heatmap')
plt.xlabel('Predicted')
plt.ylabel('True')
plt.show()
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn import datasets
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import confusion_matrix
# Load the iris dataset
iris = datasets.load_iris()
X = iris.data
y = iris.target
# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)
# Train a logistic regression model
model = LogisticRegression()
model.fit(X_train, y_train)
# Make predictions on the test set
y_pred = model.predict(X_test)
# Generate confusion matrix
conf_matrix = confusion_matrix(y_test, y_pred)
# Create a DataFrame for better visualization
conf_df = pd.DataFrame(conf_matrix, index=iris.target_names, columns=iris.target_names)
# Create a heatmap using Matplotlib's imshow
plt.imshow(conf_df, interpolation='nearest', cmap=plt.cm.Blues)
plt.title('Confusion Matrix Heatmap')
plt.colorbar()
plt.xticks(np.arange(len(iris.target_names)), iris.target_names, rotation=45)
plt.yticks(np.arange(len(iris.target_names)), iris.target_names)
plt.xlabel('Predicted')
plt.ylabel('True')
plt.show()
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn import datasets
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import confusion_matrix
# Load the iris dataset
iris = datasets.load_iris()
X = iris.data
y = iris.target
# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)
# Train a logistic regression model
model = LogisticRegression()
model.fit(X_train, y_train)
# Make predictions on the test set
y_pred = model.predict(X_test)
# Generate confusion matrix
conf_matrix = confusion_matrix(y_test, y_pred)
# Create a DataFrame for better visualization
conf_df = pd.DataFrame(conf_matrix, index=iris.target_names, columns=iris.target_names)
# Specify the plot size
plt.figure(figsize=(8, 8))
# Create a heatmap using Matplotlib's imshow
plt.imshow(conf_df, interpolation='nearest', cmap=plt.cm.Blues)
# Add annotations with actual values
for i in range(len(iris.target_names)):
for j in range(len(iris.target_names)):
plt.text(j, i, str(conf_df.iloc[i, j]), ha='center', va='center', color='w')
plt.title('Confusion Matrix Heatmap')
plt.colorbar()
plt.xticks(np.arange(len(iris.target_names)), iris.target_names, rotation=45)
plt.yticks(np.arange(len(iris.target_names)), iris.target_names)
plt.xlabel('Predicted')
plt.ylabel('True')
plt.show()
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn import datasets
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import confusion_matrix
# Load the iris dataset
iris = datasets.load_iris()
X = iris.data
y = iris.target
# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)
# Train a logistic regression model
model = LogisticRegression()
model.fit(X_train, y_train)
# Make predictions on the test set
y_pred = model.predict(X_test)
# Generate confusion matrix
conf_matrix = confusion_matrix(y_test, y_pred)
# Create a DataFrame for better visualization
conf_df = pd.DataFrame(conf_matrix, index=iris.target_names, columns=iris.target_names)
# Specify the plot size
plt.figure(figsize=(8, 8))
# Create a heatmap using Matplotlib's imshow
plt.imshow(conf_df, interpolation='nearest', cmap=plt.cm.Reds)
# Add annotations with actual values
for i in range(len(iris.target_names)):
for j in range(len(iris.target_names)):
plt.text(j, i, str(conf_df.iloc[i, j]), ha='center', va='center', color='w')
plt.title('Confusion Matrix Heatmap')
plt.colorbar()
plt.xticks(np.arange(len(iris.target_names)), iris.target_names, rotation=45)
plt.yticks(np.arange(len(iris.target_names)), iris.target_names)
plt.xlabel('Predicted')
plt.ylabel('True')
plt.show()
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn import datasets
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import confusion_matrix
# Load the iris dataset
iris = datasets.load_iris()
X = iris.data
y = iris.target
# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)
# Train a logistic regression model
model = LogisticRegression()
model.fit(X_train, y_train)
# Make predictions on the test set
y_pred = model.predict(X_test)
# Generate confusion matrix
conf_matrix = confusion_matrix(y_test, y_pred)
# Create a DataFrame for better visualization
conf_df = pd.DataFrame(conf_matrix, index=iris.target_names, columns=iris.target_names)
# Specify the plot size
plt.figure(figsize=(8, 8))
# Create a heatmap using Matplotlib's imshow
plt.imshow(conf_df, interpolation='nearest', cmap=plt.cm.Reds)
# Add annotations with actual values
for i in range(len(iris.target_names)):
for j in range(len(iris.target_names)):
plt.text(j, i, str(conf_df.iloc[i, j]), ha='center', va='center', color='w')
plt.title('Confusion Matrix Heatmap')
plt.colorbar()
plt.xticks(np.arange(len(iris.target_names)), iris.target_names, rotation=0)
plt.yticks(np.arange(len(iris.target_names)), iris.target_names)
plt.xlabel('Predicted')
plt.ylabel('True')
plt.show()
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn import datasets
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import confusion_matrix
# Load the iris dataset
iris = datasets.load_iris()
X = iris.data
y = iris.target
# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)
# Train a logistic regression model
model = LogisticRegression()
model.fit(X_train, y_train)
# Make predictions on the test set
y_pred = model.predict(X_test)
# Generate confusion matrix
conf_matrix = confusion_matrix(y_test, y_pred)
# Create a DataFrame for better visualization
conf_df = pd.DataFrame(conf_matrix, index=iris.target_names, columns=iris.target_names)
# Specify the plot size
plt.figure(figsize=(8, 8))
# Create a heatmap using Matplotlib's imshow
plt.imshow(conf_df, interpolation='nearest', cmap=plt.cm.Reds)
# Add annotations with actual values
for i in range(len(iris.target_names)):
for j in range(len(iris.target_names)):
plt.text(j, i, str(conf_df.iloc[i, j]), ha='center', va='center', color='blue')
plt.title('Confusion Matrix Heatmap')
plt.colorbar()
plt.xticks(np.arange(len(iris.target_names)), iris.target_names, rotation=0)
plt.yticks(np.arange(len(iris.target_names)), iris.target_names)
plt.xlabel('Predicted')
plt.ylabel('True')
plt.show()
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn import datasets
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import confusion_matrix
# Load the iris dataset
iris = datasets.load_iris()
X = iris.data
y = iris.target
# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)
# Train a logistic regression model
model = LogisticRegression()
model.fit(X_train, y_train)
# Make predictions on the test set
y_pred = model.predict(X_test)
# Generate confusion matrix
conf_matrix = confusion_matrix(y_test, y_pred)
# Create a DataFrame for better visualization
conf_df = pd.DataFrame(conf_matrix, index=iris.target_names, columns=iris.target_names)
# Specify the plot size
plt.figure(figsize=(8, 8))
# Create a heatmap using Matplotlib's imshow
plt.imshow(conf_df, interpolation='nearest', cmap=plt.cm.Greens)
# Add annotations with actual values
for i in range(len(iris.target_names)):
for j in range(len(iris.target_names)):
plt.text(j, i, str(conf_df.iloc[i, j]), ha='center', va='center', color='black')
plt.title('Confusion Matrix Heatmap')
plt.colorbar()
plt.xticks(np.arange(len(iris.target_names)), iris.target_names, rotation=0)
plt.yticks(np.arange(len(iris.target_names)), iris.target_names)
plt.xlabel('Predicted')
plt.ylabel('True')
plt.show()
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn import datasets
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import confusion_matrix
# Load the iris dataset
iris = datasets.load_iris()
X = iris.data
y = iris.target
# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)
# Train a logistic regression model
model = LogisticRegression()
model.fit(X_train, y_train)
# Make predictions on the test set
y_pred = model.predict(X_test)
# Generate confusion matrix
conf_matrix = confusion_matrix(y_test, y_pred)
# Create a DataFrame for better visualization
conf_df = pd.DataFrame(conf_matrix, index=iris.target_names, columns=iris.target_names)
# Specify the plot size
plt.figure(figsize=(8, 8))
# Create a heatmap using Matplotlib's imshow
plt.imshow(conf_df, interpolation='nearest', cmap=plt.cm.Greens)
# Add annotations with actual values
for i in range(len(iris.target_names)):
for j in range(len(iris.target_names)):
plt.text(j, i, str(conf_df.iloc[i, j]), ha='center', va='center')
plt.title('Confusion Matrix Heatmap')
plt.colorbar()
plt.xticks(np.arange(len(iris.target_names)), iris.target_names, rotation=0)
plt.yticks(np.arange(len(iris.target_names)), iris.target_names)
plt.xlabel('Predicted')
plt.ylabel('True')
plt.show()
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn import datasets
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import confusion_matrix
# Load the iris dataset
iris = datasets.load_iris()
X = iris.data
y = iris.target
# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)
# Train a logistic regression model
model = LogisticRegression()
model.fit(X_train, y_train)
# Make predictions on the test set
y_pred = model.predict(X_test)
# Generate confusion matrix
conf_matrix = confusion_matrix(y_test, y_pred)
# Create a DataFrame for better visualization
conf_df = pd.DataFrame(conf_matrix, index=iris.target_names, columns=iris.target_names)
# Specify the plot size
plt.figure(figsize=(8, 8))
# Create a heatmap using Matplotlib's imshow
plt.imshow(conf_df, interpolation='nearest', cmap=plt.cm.Greens)
# Add annotations with actual values
for i in range(len(iris.target_names)):
for j in range(len(iris.target_names)):
plt.text(j, i, str(conf_df.iloc[i, j]), ha='center', va='center')
plt.title('Confusion Matrix Heatmap')
plt.colorbar()
plt.xticks(np.arange(len(iris.target_names)), iris.target_names, rotation=0)
plt.yticks(np.arange(len(iris.target_names)), iris.target_names)
plt.xlabel('Predicted')
plt.ylabel('True')
plt.show()
# Calculating the accuracy of the classification
accuracy=accuracy_score(y_test,y_pred)*100
print("Accuracy of the model is {:.2f}".format(accuracy))
# Calculating the accuracy of the classification
accuracy=accuracy_score(y_test,y_pred)*100
print("Accuracy of the model is {:.2f}".format(accuracy))
reticulate::repl_python()
# Import necessary libraries
import pandas as pd
from sklearn.ensemble import IsolationForest
import matplotlib.pyplot as plt
# Load the Titanic dataset (replace 'path/to/titanic.csv' with the actual file path)
titanic = pd.read_csv(titanic.csv)
# Extract numerical features (you may choose other features based on your requirement)
numerical_features = titanic[['Age', 'Fare']]
# Handling missing values (you may need to handle other missing values based on your dataset)
numerical_features = numerical_features.dropna()
# Create and fit the Isolation Forest model
model = IsolationForest(contamination=0.01, random_state=42)
model.fit(numerical_features)
# Predict outliers (anomalies)
predictions = model.predict(numerical_features)
titanic['prediction'] = predictions
# Visualize the results
plt.scatter(numerical_features['Age'], numerical_features['Fare'], c=titanic['prediction'], cmap='viridis')
plt.title('Isolation Forest Anomaly Detection on Titanic Dataset')
plt.xlabel('Age')
plt.ylabel('Fare')
plt.show()
# Import necessary libraries
import pandas as pd
from sklearn.ensemble import IsolationForest
import matplotlib.pyplot as plt
# Load the Titanic dataset (replace 'path/to/titanic.csv' with the actual file path)
titanic = pd.read_csv('titanic.csv')
# Extract numerical features (you may choose other features based on your requirement)
numerical_features = titanic[['Age', 'Fare']]
# Handling missing values (you may need to handle other missing values based on your dataset)
numerical_features = numerical_features.dropna()
# Create and fit the Isolation Forest model
model = IsolationForest(contamination=0.01, random_state=42)
model.fit(numerical_features)
# Predict outliers (anomalies)
predictions = model.predict(numerical_features)
titanic['prediction'] = predictions
# Visualize the results
plt.scatter(numerical_features['Age'], numerical_features['Fare'], c=titanic['prediction'], cmap='viridis')
plt.title('Isolation Forest Anomaly Detection on Titanic Dataset')
plt.xlabel('Age')
plt.ylabel('Fare')
plt.show()
# Import necessary libraries
import pandas as pd
from sklearn.ensemble import IsolationForest
import matplotlib.pyplot as plt
titanic = pd.read_csv('titanic.csv')
# Extract numerical features (you may choose other features based on your requirement)
numerical_features = titanic[['Age', 'Fare']]
# Handling missing values (you may need to handle other missing values based on your dataset)
numerical_features = numerical_features.dropna()
# Create and fit the Isolation Forest model
model = IsolationForest(contamination=0.01, random_state=42)
model.fit(numerical_features)
# Predict outliers (anomalies)
predictions = model.predict(numerical_features)
titanic['prediction'] = predictions
# Separate normal and anomaly points
normal_points = numerical_features[titanic['prediction'] == 1]
anomaly_points = numerical_features[titanic['prediction'] == -1]
# Visualize the results
plt.scatter(normal_points['Age'], normal_points['Fare'], c='blue', label='Normal', alpha=0.7)
plt.scatter(anomaly_points['Age'], anomaly_points['Fare'], c='red', label='Anomaly', alpha=0.7)
plt.title('Isolation Forest Anomaly Detection on Titanic Dataset')
plt.xlabel('Age')
plt.ylabel('Fare')
# Add legend
plt.legend()
# Show the plot
plt.show()
